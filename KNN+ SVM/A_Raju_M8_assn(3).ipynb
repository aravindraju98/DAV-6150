{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification via KNN & SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Team Members:__ Surya Suresh Sriraman, Nivetha Sivakumar, Aravind Raju"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work will explore a dataset The data set is comprised of more than 14,000 observations of 1 response/dependent variable (which indicates whether or not the new insurance product was purchased) and 14 explanatory/independent\n",
    "variables. The primary objective of the project is to construct and compare/contrast a series of binary logistic regression models that predict whether or not a given insurance company customer is likely to purchase an additional insurance product. \n",
    "\n",
    "__Approach:__<br>\n",
    "- __Develop Domain Knowledge:__ Gain an understanding of the domain the data belongs to.\n",
    "- __Data Loading:__ Utilize Python and the Pandas library to load the data into a suitable DataFrame.\n",
    "- __Exploratory Data Analysis (EDA):__  Explore and analyze the dataset to identify patterns, trends, and relationships. This step involves data visualization, summary statistics, and initial insights to inform subsequent analyses.\n",
    "- __Data Preparation:__ Clean and pre process the data to handle missing values, outliers, and ensure it is in a suitable format for analysis. This step may involve feature engineering and encoding categorical variables.\n",
    "- __Prep Data Review:__ Review the prepared dataset to ensure that transformations and preprocessing steps have been applied correctly. Confirm that the data is ready for modeling.\n",
    "- __Modelling:__ The dataset is split into training and testing subsets, and build different models.\n",
    "- __Select Best Performing Model:__ Evaluate and compare the performance of different distance based models using appropriate metrics. Select the model that best fits the data and provides the most accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Note: Some data preparation steps are performed along with EDA to improve process efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score,roc_auc_score, roc_curve, auc, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Domain knowledge assign proper data types to the columns while loading the data\n",
    "column_types = {        \n",
    "        'TARGET': object,    \n",
    "        'loyalty': object,\n",
    "        'ID': 'int64',\n",
    "        'age': 'int64',\n",
    "        'city': object,\n",
    "        'LOR': 'int64',    \n",
    "        'prod_A': object,\n",
    "        'type_A': object,\n",
    "        'type_B': object,\n",
    "        'prod_B': object,    \n",
    "        'turnover_A': float,\n",
    "        'turnover_B': float,\n",
    "        'contract': object,\n",
    "        'age_P': 'int64',\n",
    "        'lor_M': 'int64'  \n",
    "    }\n",
    "\n",
    "# Load data into Pandas DataFrame\n",
    "cust_df = pd.read_csv(r\"https://raw.githubusercontent.com/s-surya-s/DAV-6150/main/M7_Data.csv\", sep = \",\", engine = 'python', dtype=column_types)\n",
    "\n",
    "# Drop unique identifier columns as they don't add any predictive value\n",
    "cust_df = cust_df.drop(columns=['ID'], axis =1)\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "cust_df = cust_df[['TARGET', 'loyalty', 'city', 'prod_A', 'type_A', 'type_B', 'prod_B', 'contract','age', 'age_P', 'lor_M', 'LOR', 'turnover_A', 'turnover_B']]\n",
    "\n",
    "# sanity check - make sure data was read in as expected\n",
    "cust_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_num = cust_df.select_dtypes(include=['int', 'float'])\n",
    "\n",
    "cust_cat = cust_df.select_dtypes(include=[object])\n",
    "\n",
    "print(\"Numeric Columns:\")\n",
    "display(cust_num.describe())\n",
    "\n",
    "print(\"Categorical Columns:\")\n",
    "display(cust_cat.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Duplicates\n",
    "'Duplicates Found' if cust_df.duplicated().any() else 'No Duplicates'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_before = len(cust_df)\n",
    "cust_df = cust_df.drop_duplicates()\n",
    "\n",
    "print(f'Number of duplicates found: {len_before - len(cust_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Nulls\n",
    "'Nulls Found' if cust_df.isnull().sum().sum() != 0 else 'No Nulls'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Univariate Analysis\n",
    "\n",
    "def Univariate_EDA(df, col):\n",
    "    '''\n",
    "    Performs Univariate Analysis\n",
    "\n",
    "    Args:\n",
    "    - df: Dataframe for Univariate analysis\n",
    "    - col: Column in the df for Univariate analysis\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    '''\n",
    "    \n",
    "    print('\\n','-'*20, col,'-'*20)\n",
    "\n",
    "    # Temporarily remove null values to view the distribution\n",
    "    df = df[df[col].notnull()]\n",
    "    \n",
    "    # get summary statistics\n",
    "    print('Summary Statistics')\n",
    "    display(df[col].describe())\n",
    "    \n",
    "    if df[col].dtype == 'object':\n",
    "        # Display unique values\n",
    "        if len(df[col].unique())<=10:\n",
    "            print('Unique Values')\n",
    "            display(df[col].unique())\n",
    "        else:\n",
    "            print('Note: The graph displays only the top 20 frequent values')\n",
    "\n",
    "        # Create a bar plot of the value counts\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.title(col)\n",
    "\n",
    "        # Get value counts for the variable\n",
    "        frequency = df[col].value_counts().head(20)\n",
    "        sns.barplot(x=frequency.index, y=frequency.values, palette=\"viridis\")\n",
    "        plt.title(col)\n",
    "        plt.ylabel(\"Counts\")\n",
    "        plt.tick_params(axis='x', rotation=90)\n",
    "\n",
    "        # Display plot\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Insights:\")\n",
    "        if len(df[col].unique()) == 1:\n",
    "            print(f\"The {col} has only one unique value, {df[col].unique()[0]}\")\n",
    "        else:\n",
    "            print(\"The {} column is comprised of {} distinct categorical values, with the most frequently occurring value being '{}'\".format(col, len(df[col].unique()),df[col].mode()[0]))\n",
    "    \n",
    "    if df[col].dtype == 'float64' or df[col].dtype == 'int64':\n",
    "\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.suptitle(col)\n",
    "\n",
    "        # Plot histogram\n",
    "        plt.subplot(1, 2, 1)\n",
    "        #sns.histplot(data=df, x=col, kde=True, color='skyblue')\n",
    "        df[col].hist()\n",
    "\n",
    "        # Plot boxplot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.boxplot(data=df, x=col, color='green')\n",
    "\n",
    "        # Display plot\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Insights:\")\n",
    "        # Check skewness and distribution\n",
    "        if df[col].median() == df[col].mean():\n",
    "            skewtext = 'the median equals the mean. Plot shows normal distribution.'\n",
    "        elif df[col].median() > df[col].mean():\n",
    "            skewtext = 'median exceeds mean. Plot shows left skewness.'\n",
    "        else:\n",
    "            skewtext = 'mean exceeds median. Plot shows right skewness.'\n",
    "\n",
    "        print(f'Summary statistics, histogram, and boxplot indicate {skewtext}\\nThe values range between {df[col].min()} and {df[col].max()}.')\n",
    "\n",
    "        # Outliers detection\n",
    "        q1 = np.quantile(df[col], 0.25)\n",
    "        q3 = np.quantile(df[col], 0.75)\n",
    "        iqr = q3 - q1\n",
    "        upper_bound = q3 + (1.5 * iqr)\n",
    "        lower_bound = q1 - (1.5 * iqr)\n",
    "        outlier = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "\n",
    "        # Display outliers information\n",
    "        if outlier.sum() > 0:\n",
    "            print('Outliers Detected!')\n",
    "            print('Outliers%: {}'.format(round(100 * outlier.mean(), 2)))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cust_df.columns:    \n",
    "    Univariate_EDA(cust_df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric vs Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = cust_df.corr()\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Correlation Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Insights__ : The heatmap shows the high correlation between the following variables:\n",
    "1) age_p and age\n",
    "2) lor_M and LOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target vs Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 1\n",
    "target = 'TARGET'\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.suptitle('Target vs Numeric Columns')\n",
    "\n",
    "for col in cust_num.columns:  \n",
    "\n",
    "    plt.subplot(1,6,pos)\n",
    "    sns.boxplot(x=target, y=col, data=cust_df)\n",
    "    plt.title(target+' vs '+col)\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    pos += 1\n",
    "    \n",
    "plt.tight_layout()   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Insights__ : The box plot reveals the following insights:\n",
    "1) Target vs age : People who are more likely to purchase a new product are mostly between the age range of 30 to 50.\n",
    "2) Target vs age_p : People who are more likely to purchase a new product are mostly between the age range of 30 to 50.\n",
    "3) Target vs lor_M : People who are more likely to purchase a new product are mostly between the range of 2 to 15 months of relationship with the company.\n",
    "4) Target vs LOR : People who are more likely to purchase a new product are mostly between the range of 2 to 15 months of relationship with the company.\n",
    "5) Target vs turnover_A : The turnover of product A has no specific pattern to link directly with target variable.\n",
    "6) Target vs turnover_B : The turnover of product B has no specific pattern to link directly with target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target vs Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 1\n",
    "target = 'TARGET'\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.suptitle('Target vs Categorical Columns')\n",
    "\n",
    "for col in cust_cat.columns[1:]:  \n",
    "\n",
    "    plt.subplot(2,4,pos)\n",
    "    sns.countplot(x=col, hue=target, data=cust_df)\n",
    "    plt.title(target+' vs '+col)\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    if pos%4 !=1:\n",
    "        plt.legend().set_visible(False) \n",
    "    \n",
    "    pos += 1\n",
    "    \n",
    "plt.tight_layout()   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Insights__ : The bar plot reveals the following insights:\n",
    "1) Target vs loyalty : Unlikely People with loyalty of 3 are more likely to not purchase a new product.\n",
    "2) Target vs city : There is no specific relationship between the city and target variable.\n",
    "3) Target vs prod_A : People who purchase product A are more likely to not purchase a new product.\n",
    "4) Target vs type_A : People who purchase product A of type 3 are more likely to not purchase a new product.\n",
    "5) Target vs type_B : People who purchase product B of type 3 are more likely to not purchase a new product.\n",
    "6) Target vs prod_B : People who purchase product B are more likely to not purchase a new product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From EDA we found the following\n",
    "\n",
    "- The contract column has only one value. We can drop the column as it does not have any variance.\n",
    "- The city column 97.8% values as '2'. We can drop the column as it has very low variance.\n",
    "- The following columns are 100% correlated. We can retain any one highly correalted column to prevent multicollinearity.\n",
    "    - age, age_P\n",
    "    - lor_M, LOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df = cust_df.drop(columns=['contract', 'city', 'age_P', 'lor_M'], axis =1)\n",
    "\n",
    "# Sanity Check\n",
    "cust_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names and their corresponding winsorization limits\n",
    "# The limits are derived from EDA insights\n",
    "col_limits = {'age' : 0.022,\n",
    "           'turnover_A' : 0.0364,\n",
    "           'turnover_B' : 0.091}\n",
    "\n",
    "# Iterate through the columns and apply winsorization\n",
    "for col in col_limits.keys():   \n",
    "    cust_df[col] = winsorize(cust_df[col], limits=[None, col_limits[col]])\n",
    "    \n",
    "# Sanity Check - Outliers      \n",
    "pos = 1\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.title('Sanity Check - Outliers')\n",
    "\n",
    "for col in col_limits.keys():  \n",
    "\n",
    "    plt.subplot(1,3,pos)\n",
    "    sns.boxplot(data=cust_df, y=col, color='green')\n",
    "    pos += 1\n",
    "    \n",
    "plt.tight_layout()   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping Sparse Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create bins to categorize the customers as existing or new based on their length of relationship. The LOR column is mostly filled with 0 and 1 compared to other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label customers with LOR less than 1 year as 'New' and remaining as 'Existing'\n",
    "cust_df['LOR'] = cust_df['LOR'].apply(lambda x: 'New' if x < 1 else 'Existing')\n",
    "\n",
    "# Sanity Check\n",
    "cust_df['LOR'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to one-hot encode\n",
    "encode_cols = cust_df.select_dtypes(include=[object]).columns\n",
    "\n",
    "# Apply one-hot encoding to the specified columns\n",
    "encoded_df = pd.get_dummies(cust_df[encode_cols], drop_first=True)\n",
    "\n",
    "# Drop the original columns from the DataFrame\n",
    "cust_df.drop(columns=encode_cols, inplace=True)\n",
    "\n",
    "# Concatenate the original DataFrame with the one-hot encoded columns\n",
    "cust_df = pd.concat([cust_df, encoded_df], axis=1)\n",
    "\n",
    "cust_df.rename(columns = {'TARGET_Y':'TARGET'}, inplace =True)\n",
    "\n",
    "cust_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanatory Variable\n",
    "X = cust_df.copy().drop('TARGET', axis=1)\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response Variable\n",
    "y = cust_df['TARGET']\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE + ENN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE + ENN is an hybrid technique. SMOTE oversamples the minority class by creating synthetic data points. ENN undersamples both the majority and minority classes by identifying and removing noisy or irrelevant data points Integrating these techniques results in a more clear and concise class separation.\n",
    "\n",
    "Ref: https://www.analyticsvidhya.com/blog/2020/10/overcoming-class-imbalance-using-smote-techniques/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y)\n",
    "print(f'Before {Counter(y)}')\n",
    "\n",
    "smenn = SMOTEENN()\n",
    "X, y = smenn.fit_resample(X,y)\n",
    "\n",
    "print(f'After {Counter(y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the VarianceThreshold object (remove features with variance below the threshold)\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "\n",
    "# Fit the selector to the data\n",
    "selector.fit(X)\n",
    "\n",
    "selector.get_support()\n",
    "\n",
    "#get the list of eaturs with low variance\n",
    "lowvar_col = [column for column in X.columns if column not in X.columns[selector.get_support()]]\n",
    "\n",
    "print(f\"Features with Low Variance:{lowvar_col}\")\n",
    "\n",
    "#drop low variance columns\n",
    "X = X.drop(lowvar_col,axis=1)\n",
    "\n",
    "print(f\"Shape of dataframe after removing the low variance columns:{X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = mutual_info_regression(X, y)\n",
    "\n",
    "mic_df = pd.DataFrame({\"feature\": X.columns, \"vimp\": mic}).sort_values(by=\"vimp\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data = mic_df, x='feature', y='vimp', color='red')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_top_columns =  SelectPercentile(mutual_info_regression, percentile=50)\n",
    "\n",
    "selected_top_columns.fit(X, y)\n",
    "\n",
    "X = X[X.columns[selected_top_columns.get_support()]].reset_index(drop = True)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['age','turnover_A', 'turnover_B']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the selected columns\n",
    "scaled_columns = scaler.fit_transform(X[columns_to_scale])\n",
    "\n",
    "# Create a DataFrame with scaled columns\n",
    "scaled_df = pd.DataFrame(scaled_columns, columns=columns_to_scale)\n",
    "\n",
    "# Replace the scaled columns in the original DataFrame\n",
    "X[columns_to_scale] = scaled_df\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepped Data Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with prepped data to perform EDA\n",
    "prep_eda_df = pd.concat([X, y], axis=1)\n",
    "prep_eda_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_eda_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "pos = 1\n",
    "for col in ['age', 'turnover_A', 'turnover_B']:\n",
    "\n",
    "    plt.subplot(3,2,pos)\n",
    "    sns.histplot(data=prep_eda_df, x=col)    \n",
    "    pos+=1\n",
    "    \n",
    "    plt.subplot(3,2,pos)\n",
    "    sns.boxplot(data=prep_eda_df, x=col)\n",
    "    pos+=1\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "frequency = prep_eda_df['TARGET'].value_counts()\n",
    "sns.barplot(x=frequency.index, y=frequency.values, palette=\"viridis\")\n",
    "plt.title('TARGET')\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 1\n",
    "target = 'TARGET'\n",
    "plt.figure(figsize=(10, 3))\n",
    "\n",
    "for col in prep_eda_df.columns.difference(['age', 'turnover_A', 'turnover_B', 'TARGET']):  \n",
    "\n",
    "    plt.subplot(1,3,pos)\n",
    "    sns.countplot(x=col, hue=target, data=prep_eda_df)\n",
    "    plt.title(target+' vs '+col)\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    pos += 1\n",
    "    \n",
    "plt.tight_layout()   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN + SVM Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the train-test split (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reset the index for the training set\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "# Reset the index for the testing set\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print(\"Training set shapes - X: {}, y: {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Testing set shapes - X: {}, y: {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the K-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range of neighbors (K) for cross-validation\n",
    "neighbors = range(1, 50)\n",
    "\n",
    "# Perform cross-validation for each value of K\n",
    "cv_scores = []\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')  # 5-fold cross-validation\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# Plot cross-validation curve\n",
    "plt.figure()\n",
    "plt.plot(neighbors, cv_scores, marker='o')\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.ylabel('Cross-Validation Accuracy')\n",
    "plt.title('Cross-Validation Curve for KNN')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select K-value as 3 as it has high accuracy and has reduced chance of overfitting compared to smaller k-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model(X_train, y_train, X_test, y_test, features):\n",
    "    \"\"\"\n",
    "    Train a k-Nearest Neighbors (KNN) model, make predictions, and evaluate its performance.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: Training features\n",
    "    - y_train: Training labels\n",
    "    - X_test: Testing features\n",
    "    - y_test: Testing labels\n",
    "    - features: List of feature names to use in training the model\n",
    "\n",
    "    Returns:\n",
    "    - Accuracy score on the test set\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a KNN model\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "    # Train the KNN model using the specified features\n",
    "    knn.fit(X_train[features], y_train)   \n",
    "\n",
    "    y_pred = knn.predict(X_test[features])\n",
    "        \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    \n",
    "    return {'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "            'Precision': round(precision_score(y_test, y_pred),2),\n",
    "            'Recall': round(recall_score(y_test, y_pred),2),\n",
    "            'F1-Score': round(f1_score(y_test, y_pred),2)}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a SVM model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model1 = knn_model(X_train, y_train, X_test, y_test, X_train.columns)\n",
    "\n",
    "print(knn_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a KNN model with selected 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model2 = knn_model(X_train, y_train, X_test, y_test, ['age', 'turnover_A', 'turnover_B'])\n",
    "\n",
    "print(knn_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a KNN model with selected 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model3 = knn_model(X_train, y_train, X_test, y_test, ['turnover_A', 'turnover_B'])\n",
    "\n",
    "print(knn_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_model(X_train, y_train, X_test, y_test, features):\n",
    "    \"\"\"\n",
    "    Train an SVM model and evaluate its accuracy.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: Training features\n",
    "    - y_train: Training labels\n",
    "    - X_test: Testing features\n",
    "    - y_test: Testing labels\n",
    "    - features: List of feature names to use in training the model\n",
    "\n",
    "    Returns:\n",
    "    - Accuracy score on the test set\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an SVM model with probability estimates enabled\n",
    "    svc = SVC(random_state=42, probability=True)\n",
    "\n",
    "    # Train the SVM model using the specified features\n",
    "    svc.fit(X_train[features], y_train)\n",
    "        \n",
    "    # y_pred = svc.predict(X_test[features])\n",
    "    y_pred = svc.predict(X_test[features])\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    \n",
    "    # Evaluate the model on the test set and calculate accuracy\n",
    "    \n",
    "    return {'Accuracy': round(accuracy_score(y_test, y_pred),2),\n",
    "            'Precision': round(precision_score(y_test, y_pred),2),\n",
    "            'Recall': round(recall_score(y_test, y_pred),2),\n",
    "            'F1-Score': round(f1_score(y_test, y_pred),2)}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a SVM model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model1 = svm_model(X_train, y_train, X_test, y_test, X_train.columns)\n",
    "\n",
    "print(svm_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a SVM model with selected 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model2 = svm_model(X_train, y_train, X_test, y_test, ['age', 'turnover_A', 'turnover_B'])\n",
    "\n",
    "print(svm_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a SVM model with selected 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model3 = svm_model(X_train, y_train, X_test, y_test, ['turnover_A', 'turnover_B'])\n",
    "\n",
    "print(svm_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = pd.DataFrame()\n",
    "\n",
    "model_eval = model_eval.append(pd.Series(knn_model1, name='KNN Model 1'))\n",
    "model_eval = model_eval.append(pd.Series(knn_model2, name='KNN Model 2'))\n",
    "model_eval = model_eval.append(pd.Series(knn_model3, name='KNN Model 3'))\n",
    "\n",
    "model_eval = model_eval.append(pd.Series(svm_model1, name='SVM Model 1'))\n",
    "model_eval = model_eval.append(pd.Series(svm_model2, name='SVM Model 2'))\n",
    "model_eval = model_eval.append(pd.Series(svm_model3, name='SVM Model 3'))\n",
    "\n",
    "model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Null Error Rate: {round(y_train.value_counts(normalize=True).max(),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the models are performing well when compared to the null error rate.\n",
    "\n",
    " Considering all the metrics __KNN model 2__ with ['age', 'turnover_A', 'turnover_B'] features is performing well and it is the best choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with logistic regression model from M7"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing logistic regression model was __Model 1__. \n",
    "\n",
    "On comparison, even the low performing KNN and SVM models outperforms the best performing logistic regression model across all metrics. This highlights the robustness of the distance-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exploratory data analysis (EDA) played a pivotal role in identifying outliers and correlated features. Leveraging these insights, we strategically removed insignificant columns. Subsequently, employing the winsorize method, we rectified outliers and aggregated sparse categories. \n",
    "\n",
    "In feature engineering, we encoded categorical columns into dummy variables. We used SMOTE ENN to handle class imbalance within the target column. Thereafter, utilizing variance threshold and mutual information, we conducted feature selection. Following this, a post-EDA was performed on the prepared dataset.\n",
    "\n",
    "Finally, we built 3 different KNN and SVM models with different sets of features. \n",
    "\n",
    "Throughout the process, we curated the dataset, addressing outliers, categorical encoding, and class imbalances. Leveraging advanced techniques like SMOTE ENN and feature selection, we optimized model performance, ultimately recognizing our KNN model 2's dominance in predictive accuracy and stability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
